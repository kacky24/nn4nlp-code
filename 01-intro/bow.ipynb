{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "import random\n",
    "import dynet as dy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to read in the corpus\n",
    "w2i = defaultdict(lambda: len(w2i))\n",
    "t2i = defaultdict(lambda: len(t2i))\n",
    "UNK = w2i[\"<unk>\"]\n",
    "def read_dataset(filename):\n",
    "  with open(filename, \"r\") as f:\n",
    "    for line in f:\n",
    "      tag, words = line.lower().strip().split(\" ||| \")\n",
    "      yield ([w2i[x] for x in words.split(\" \")], t2i[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "train = list(read_dataset(\"../data/classes/train.txt\"))\n",
    "# 第２引数のw2iは普通のdictのコンストラクタに与えられる\n",
    "# これ以降登録されていない語にUNK(0)を返すようにする\n",
    "w2i = defaultdict(lambda: UNK, w2i)\n",
    "dev = list(read_dataset(\"../data/classes/test.txt\"))\n",
    "nwords = len(w2i)\n",
    "ntags = len(t2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start DyNet and define trainer\n",
    "model = dy.Model()\n",
    "trainer = dy.AdamTrainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "W_sm = model.add_lookup_parameters((nwords, ntags)) # Word weights\n",
    "b_sm = model.add_parameters((ntags))                # Softmax bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to calculate scores for one value\n",
    "def calc_scores(words):\n",
    "  dy.renew_cg()   # build new computation graph\n",
    "  score = dy.esum([dy.lookup(W_sm, x) for x in words])  # dy.esum: sum, \n",
    "  b_sm_exp = dy.parameter(b_sm)  # dy.parameter: load tensor to computational graph\n",
    "  return score + b_sm_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: train loss/sent=2.3897, time=0.35s\n",
      "iter 0: test acc=0.2615\n",
      "iter 1: train loss/sent=2.0018, time=0.33s\n",
      "iter 1: test acc=0.2701\n",
      "iter 2: train loss/sent=1.8110, time=0.32s\n",
      "iter 2: test acc=0.2819\n",
      "iter 3: train loss/sent=1.6794, time=0.31s\n",
      "iter 3: test acc=0.2869\n",
      "iter 4: train loss/sent=1.5726, time=0.31s\n",
      "iter 4: test acc=0.2959\n",
      "iter 5: train loss/sent=1.4860, time=0.38s\n",
      "iter 5: test acc=0.3005\n",
      "iter 6: train loss/sent=1.4112, time=0.33s\n",
      "iter 6: test acc=0.3090\n",
      "iter 7: train loss/sent=1.3454, time=0.35s\n",
      "iter 7: test acc=0.3077\n",
      "iter 8: train loss/sent=1.2875, time=0.32s\n",
      "iter 8: test acc=0.3145\n",
      "iter 9: train loss/sent=1.2350, time=0.32s\n",
      "iter 9: test acc=0.3190\n",
      "iter 10: train loss/sent=1.1876, time=0.32s\n",
      "iter 10: test acc=0.3217\n",
      "iter 11: train loss/sent=1.1446, time=0.32s\n",
      "iter 11: test acc=0.3294\n",
      "iter 12: train loss/sent=1.1050, time=0.32s\n",
      "iter 12: test acc=0.3222\n",
      "iter 13: train loss/sent=1.0680, time=0.32s\n",
      "iter 13: test acc=0.3321\n",
      "iter 14: train loss/sent=1.0345, time=0.38s\n",
      "iter 14: test acc=0.3317\n",
      "iter 15: train loss/sent=1.0029, time=0.33s\n",
      "iter 15: test acc=0.3339\n",
      "iter 16: train loss/sent=0.9736, time=0.34s\n",
      "iter 16: test acc=0.3271\n",
      "iter 17: train loss/sent=0.9463, time=0.32s\n",
      "iter 17: test acc=0.3330\n",
      "iter 18: train loss/sent=0.9202, time=0.32s\n",
      "iter 18: test acc=0.3271\n",
      "iter 19: train loss/sent=0.8963, time=0.32s\n",
      "iter 19: test acc=0.3321\n",
      "iter 20: train loss/sent=0.8733, time=0.31s\n",
      "iter 20: test acc=0.3276\n",
      "iter 21: train loss/sent=0.8521, time=0.30s\n",
      "iter 21: test acc=0.3371\n",
      "iter 22: train loss/sent=0.8316, time=0.32s\n",
      "iter 22: test acc=0.3326\n",
      "iter 23: train loss/sent=0.8126, time=0.34s\n",
      "iter 23: test acc=0.3303\n",
      "iter 24: train loss/sent=0.7948, time=0.37s\n",
      "iter 24: test acc=0.3385\n",
      "iter 25: train loss/sent=0.7776, time=0.37s\n",
      "iter 25: test acc=0.3430\n",
      "iter 26: train loss/sent=0.7608, time=0.36s\n",
      "iter 26: test acc=0.3367\n",
      "iter 27: train loss/sent=0.7451, time=0.35s\n",
      "iter 27: test acc=0.3394\n",
      "iter 28: train loss/sent=0.7305, time=0.34s\n",
      "iter 28: test acc=0.3462\n",
      "iter 29: train loss/sent=0.7161, time=0.31s\n",
      "iter 29: test acc=0.3371\n",
      "iter 30: train loss/sent=0.7029, time=0.31s\n",
      "iter 30: test acc=0.3443\n",
      "iter 31: train loss/sent=0.6902, time=0.31s\n",
      "iter 31: test acc=0.3484\n",
      "iter 32: train loss/sent=0.6782, time=0.30s\n",
      "iter 32: test acc=0.3452\n",
      "iter 33: train loss/sent=0.6657, time=0.33s\n",
      "iter 33: test acc=0.3493\n",
      "iter 34: train loss/sent=0.6548, time=0.32s\n",
      "iter 34: test acc=0.3466\n",
      "iter 35: train loss/sent=0.6439, time=0.33s\n",
      "iter 35: test acc=0.3498\n",
      "iter 36: train loss/sent=0.6335, time=0.35s\n",
      "iter 36: test acc=0.3480\n",
      "iter 37: train loss/sent=0.6233, time=0.32s\n",
      "iter 37: test acc=0.3466\n",
      "iter 38: train loss/sent=0.6135, time=0.33s\n",
      "iter 38: test acc=0.3557\n",
      "iter 39: train loss/sent=0.6044, time=0.36s\n",
      "iter 39: test acc=0.3475\n",
      "iter 40: train loss/sent=0.5949, time=0.39s\n",
      "iter 40: test acc=0.3484\n",
      "iter 41: train loss/sent=0.5868, time=0.34s\n",
      "iter 41: test acc=0.3493\n",
      "iter 42: train loss/sent=0.5787, time=0.38s\n",
      "iter 42: test acc=0.3516\n",
      "iter 43: train loss/sent=0.5702, time=0.34s\n",
      "iter 43: test acc=0.3502\n",
      "iter 44: train loss/sent=0.5624, time=0.38s\n",
      "iter 44: test acc=0.3502\n",
      "iter 45: train loss/sent=0.5549, time=0.39s\n",
      "iter 45: test acc=0.3475\n",
      "iter 46: train loss/sent=0.5475, time=0.36s\n",
      "iter 46: test acc=0.3502\n",
      "iter 47: train loss/sent=0.5408, time=0.32s\n",
      "iter 47: test acc=0.3538\n",
      "iter 48: train loss/sent=0.5339, time=0.35s\n",
      "iter 48: test acc=0.3516\n",
      "iter 49: train loss/sent=0.5271, time=0.34s\n",
      "iter 49: test acc=0.3516\n",
      "iter 50: train loss/sent=0.5205, time=0.31s\n",
      "iter 50: test acc=0.3484\n",
      "iter 51: train loss/sent=0.5140, time=0.31s\n",
      "iter 51: test acc=0.3520\n",
      "iter 52: train loss/sent=0.5086, time=0.31s\n",
      "iter 52: test acc=0.3548\n",
      "iter 53: train loss/sent=0.5028, time=0.31s\n",
      "iter 53: test acc=0.3538\n",
      "iter 54: train loss/sent=0.4968, time=0.31s\n",
      "iter 54: test acc=0.3534\n",
      "iter 55: train loss/sent=0.4911, time=0.31s\n",
      "iter 55: test acc=0.3548\n",
      "iter 56: train loss/sent=0.4855, time=0.31s\n",
      "iter 56: test acc=0.3538\n",
      "iter 57: train loss/sent=0.4805, time=0.31s\n",
      "iter 57: test acc=0.3588\n",
      "iter 58: train loss/sent=0.4752, time=0.37s\n",
      "iter 58: test acc=0.3570\n",
      "iter 59: train loss/sent=0.4702, time=0.32s\n",
      "iter 59: test acc=0.3575\n",
      "iter 60: train loss/sent=0.4653, time=0.35s\n",
      "iter 60: test acc=0.3593\n",
      "iter 61: train loss/sent=0.4605, time=0.34s\n",
      "iter 61: test acc=0.3593\n",
      "iter 62: train loss/sent=0.4557, time=0.31s\n",
      "iter 62: test acc=0.3579\n",
      "iter 63: train loss/sent=0.4515, time=0.32s\n",
      "iter 63: test acc=0.3584\n",
      "iter 64: train loss/sent=0.4469, time=0.32s\n",
      "iter 64: test acc=0.3566\n",
      "iter 65: train loss/sent=0.4429, time=0.32s\n",
      "iter 65: test acc=0.3538\n",
      "iter 66: train loss/sent=0.4385, time=0.32s\n",
      "iter 66: test acc=0.3575\n",
      "iter 67: train loss/sent=0.4340, time=0.32s\n",
      "iter 67: test acc=0.3575\n",
      "iter 68: train loss/sent=0.4301, time=0.33s\n",
      "iter 68: test acc=0.3602\n",
      "iter 69: train loss/sent=0.4265, time=0.33s\n",
      "iter 69: test acc=0.3638\n",
      "iter 70: train loss/sent=0.4224, time=0.33s\n",
      "iter 70: test acc=0.3606\n",
      "iter 71: train loss/sent=0.4186, time=0.33s\n",
      "iter 71: test acc=0.3575\n",
      "iter 72: train loss/sent=0.4152, time=0.32s\n",
      "iter 72: test acc=0.3561\n",
      "iter 73: train loss/sent=0.4112, time=0.32s\n",
      "iter 73: test acc=0.3624\n",
      "iter 74: train loss/sent=0.4081, time=0.33s\n",
      "iter 74: test acc=0.3570\n",
      "iter 75: train loss/sent=0.4043, time=0.34s\n",
      "iter 75: test acc=0.3570\n",
      "iter 76: train loss/sent=0.4012, time=0.33s\n",
      "iter 76: test acc=0.3579\n",
      "iter 77: train loss/sent=0.3977, time=0.33s\n",
      "iter 77: test acc=0.3606\n",
      "iter 78: train loss/sent=0.3943, time=0.32s\n",
      "iter 78: test acc=0.3597\n",
      "iter 79: train loss/sent=0.3910, time=0.34s\n",
      "iter 79: test acc=0.3597\n",
      "iter 80: train loss/sent=0.3882, time=0.32s\n",
      "iter 80: test acc=0.3620\n",
      "iter 81: train loss/sent=0.3850, time=0.38s\n",
      "iter 81: test acc=0.3647\n",
      "iter 82: train loss/sent=0.3817, time=0.34s\n",
      "iter 82: test acc=0.3611\n",
      "iter 83: train loss/sent=0.3788, time=0.37s\n",
      "iter 83: test acc=0.3633\n",
      "iter 84: train loss/sent=0.3759, time=0.34s\n",
      "iter 84: test acc=0.3652\n",
      "iter 85: train loss/sent=0.3729, time=0.39s\n",
      "iter 85: test acc=0.3620\n",
      "iter 86: train loss/sent=0.3705, time=0.33s\n",
      "iter 86: test acc=0.3647\n",
      "iter 87: train loss/sent=0.3675, time=0.37s\n",
      "iter 87: test acc=0.3679\n",
      "iter 88: train loss/sent=0.3643, time=0.34s\n",
      "iter 88: test acc=0.3656\n",
      "iter 89: train loss/sent=0.3620, time=0.36s\n",
      "iter 89: test acc=0.3679\n",
      "iter 90: train loss/sent=0.3597, time=0.34s\n",
      "iter 90: test acc=0.3638\n",
      "iter 91: train loss/sent=0.3567, time=0.36s\n",
      "iter 91: test acc=0.3661\n",
      "iter 92: train loss/sent=0.3538, time=0.32s\n",
      "iter 92: test acc=0.3670\n",
      "iter 93: train loss/sent=0.3519, time=0.32s\n",
      "iter 93: test acc=0.3633\n",
      "iter 94: train loss/sent=0.3494, time=0.33s\n",
      "iter 94: test acc=0.3679\n",
      "iter 95: train loss/sent=0.3469, time=0.33s\n",
      "iter 95: test acc=0.3647\n",
      "iter 96: train loss/sent=0.3444, time=0.33s\n",
      "iter 96: test acc=0.3679\n",
      "iter 97: train loss/sent=0.3421, time=0.32s\n",
      "iter 97: test acc=0.3688\n",
      "iter 98: train loss/sent=0.3395, time=0.32s\n",
      "iter 98: test acc=0.3679\n",
      "iter 99: train loss/sent=0.3372, time=0.33s\n",
      "iter 99: test acc=0.3652\n"
     ]
    }
   ],
   "source": [
    "for ITER in range(100):\n",
    "  # Perform training\n",
    "  random.shuffle(train)\n",
    "  train_loss = 0.0\n",
    "  start = time.time()\n",
    "  for words, tag in train:\n",
    "    # dy.pick: Picking values from vector expressions\n",
    "    # dy.pick(e1, k) <-> e1[k]\n",
    "    # dy.pickneglogsoftmax: neglogsoftmax -> pick (in this case dy.pick(~, tag))\n",
    "    my_loss = dy.pickneglogsoftmax(calc_scores(words), tag)\n",
    "    train_loss += my_loss.value()\n",
    "    my_loss.backward()\n",
    "    trainer.update()\n",
    "  print(\"iter %r: train loss/sent=%.4f, time=%.2fs\" % (ITER, train_loss/len(train), time.time()-start))\n",
    "  # Perform testing\n",
    "  test_correct = 0.0\n",
    "  for words, tag in dev:\n",
    "    scores = calc_scores(words).npvalue()\n",
    "    predict = np.argmax(scores)\n",
    "    if predict == tag:\n",
    "      test_correct += 1\n",
    "  print(\"iter %r: test acc=%.4f\" % (ITER, test_correct/len(dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
